import os
from typing import List, Iterable

import streamlit as st
from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.tools import WikipediaQueryRun, DuckDuckGoSearchResults
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_core.documents import Document
from langchain_core.prompts import BasePromptTemplate
from langchain_core.retrievers import BaseRetriever
from langchain_core.tools import create_retriever_tool
from langchain_core.vectorstores import VectorStore, InMemoryVectorStore
from streamlit.runtime.uploaded_file_manager import UploadedFile
from langchain.text_splitter import RecursiveCharacterTextSplitter
from examples.factory.ai_factory import create_ai


def create_vector_store() -> VectorStore:
    # return Chroma("langchain_store", DashScopeEmbeddings())
    return InMemoryVectorStore(DashScopeEmbeddings())


# Write uploaded file in temp dir
def write_file(fp: str, content: bytes):
    try:
        with open(fp, 'wb') as file:
            file.write(content)
        return True
    except Exception as e:
        print(f"Error occurred while writing the file: {e}")
        return False


# loading PDF, DOCX and TXT files as LangChain Documents
def load_documents(file: str) -> list[Document]:
    _, extension = os.path.splitext(file)
    if extension == '.pdf':
        from langchain_community.document_loaders import PyPDFLoader
        print(f'Loading {file}')
        loader = PyPDFLoader(file)
    elif extension == '.docx':
        from langchain_community.document_loaders import Docx2txtLoader
        print(f'Loading {file}')
        loader = Docx2txtLoader(file)
    elif extension == '.txt':
        from langchain_community.document_loaders import TextLoader
        loader = TextLoader(file)
    else:
        print('Document format is not supported!')
        return []
    return loader.load()


# splitting data in chunks
def split_documents(data: Iterable[Document], chunk_size=2000, chunk_overlap=200) -> List[Document]:
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    return text_splitter.split_documents(data)

# clear the chat history from streamlit session state
def clear_history():
    pass
    # if 'history' in st.session_state:
    # del st.session_state['history']


# calculate embedding cost using tiktoken
def calculate_embedding_cost(texts: Iterable[Document]):
    import tiktoken
    enc = tiktoken.encoding_for_model('text-embedding-ada-002')
    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])
    return total_tokens, total_tokens / 1000 * 0.0004


def create_tmp_dir(tmp_dir: str):
    os.makedirs(tmp_dir, exist_ok=True)


@st.cache_resource(ttl="1d")
def create_prompt() -> BasePromptTemplate:
    # æŒ‡ä»¤æ¨¡æ¿
    instructions = """ä½ æ˜¯ä¸€ä¸ªè®¾è®¡ç”¨äºæŸ»è¯¢æ–‡æ¡£æ¥å›ç­”é—®é¢˜çš„ä»£ç†æ‚¨å¯ä»¥ä½¿ç”¨æ–‡æ¡£æ£€ç´¢å·¥å…·ï¼Œ
    å¹¶ä¼˜å…ˆåŸºäºæ£€ç´¢å†…å®¹æ¥å›ç­”é—®é¢˜ï¼Œå¦‚æœä»æ–‡æ¡£ä¸­æ‰¾ä¸åˆ°ä»»ä½•ä¿¡æ¯ç”¨äºå›ç­”é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡å…¶ä»–å·¥å…·æœç´¢ç­”æ¡ˆï¼Œå¦‚æœæ‰€æœ‰çš„å·¥å…·éƒ½ä¸èƒ½æ‰¾åˆ°ç­”æ¡ˆï¼Œåˆ™åªéœ€è¿”å›â€œæŠ±æ­‰ï¼Œè¿™ä¸ªé—®é¢˜æˆ‘è¿˜ä¸çŸ¥é“ã€‚â€ä½œä¸ºç­”æ¡ˆã€‚
    ä½ éœ€è¦ä»¥JSONç»“æ„è¿”å›ã€‚JSONç»“æ„ä½“åŒ…å«outputå­—æ®µï¼Œoutputæ˜¯ä½ ç»™ç”¨æˆ·è¿”å›çš„å†…å®¹ã€‚
    """
    base_prompt = hub.pull("hwchase17/react")
    return base_prompt.partial(instructions=instructions)


def create_agent(retriever: BaseRetriever) -> AgentExecutor:
    msgs = StreamlitChatMessageHistory()
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        output_key="output",
        chat_memory=msgs
    )
    tool = create_retriever_tool(
        retriever=retriever,
        name="æ–‡æ¡£æ£€ç´¢",
        description="ç”¨äºæ£€ç´¢ç”¨æˆ·æå‡ºçš„é—®é¢˜ï¼Œå¹¶åŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹è¿›è¡Œå›å¤"
    )

    tools = [
        tool,
        WikipediaQueryRun(
            name="wiki-tool",
            description="look up things in wikipedia",
            api_wrapper=WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100),
        ),
        DuckDuckGoSearchResults()
    ]
    react_agent = create_react_agent(create_ai(), tools, create_prompt())
    return AgentExecutor(
        agent=react_agent,
        tools=tools,
        memory=memory,
        verbose=True,
        handle_parsing_errors="æ²¡æœ‰ä»çŸ¥è¯†åº“æ£€ç´¢åˆ°ç›¸ä¼¼çš„å†…å®¹"
    )


def init():
    if "vs" not in st.session_state:
        st.session_state.vs = create_vector_store()
    if "messages" not in st.session_state:
        st.session_state.messages = []
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

def upload_file(uf: UploadedFile, chunk_size: int):
    parent_path = "/tmp/agent"
    create_tmp_dir(parent_path)
    # writing the file from RAM to the current directory on disk
    file_path = os.path.join(parent_path, uf.name)
    print(f'Writing {uf.name} to {file_path}')
    write_file(file_path, uf.read())
    documents = load_documents(file_path)
    chunk_docs = split_documents(documents, chunk_size=chunk_size)
    st.session_state.vs.add_documents(chunk_docs)
    st.write(f'Chunk size: {chunk_size}, Chunks: {len(chunk_docs)}')
    tokens, embedding_cost = calculate_embedding_cost(chunk_docs)
    st.write(f"Embedding cost: {embedding_cost:.4f}, total tokens:{tokens}")
    st.success('File uploaded, chunked and embedded successfully.')


if __name__ == "__main__":
    init()
    # st.image('img.png')
    st.subheader('QwenğŸ¤–')
    with st.sidebar:
        # file uploader widget
        uploaded_file = st.file_uploader('Upload a file:', type=['pdf', 'docx', 'txt'])
        # chunk size number widget
        chunks = st.number_input('Chunk size:', min_value=2000, max_value=4000, value=2000, on_change=clear_history)

        # add data button widget
        add_data = st.button('Add Data', on_click=clear_history)
        if uploaded_file and add_data:  # if the user browsed a file
            with st.spinner('Reading, chunking and embedding file ...'):
                upload_file(uploaded_file, chunks)

    q = st.chat_input(placeholder="è¯·é—®æˆ‘ä»»ä½•å…³äºæ–‡ç« çš„é—®é¢˜")
    if q:
        st.chat_message("user").markdown(q)
        st.session_state.messages.append({"role": "user", "content": q})
        collected_messages = ""
        with st.chat_message("assistant"):
            output_placeholder = st.empty()
            st_cb = StreamlitCallbackHandler(st.container())
            agent = create_agent(st.session_state.vs.as_retriever())
            stream = agent.stream({"input": q}, config={"callbacks": [st_cb]})
            for chunk in stream:
                if "output" in chunk:
                    collected_messages += chunk.get("output")
                    output_placeholder.markdown(collected_messages + "â–Œ")
            output_placeholder.markdown(collected_messages)
            st.session_state.messages.append({"role": "assistant", "content": collected_messages})
